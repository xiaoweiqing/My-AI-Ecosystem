# ==============================================================================
#                      å‘¨æœŸæ€§å¤ç›˜AI (Periodic Review AI) v5.0
#                      (ChromaDB Memory & History Refill Edition)
# ==============================================================================
# ç‰ˆæœ¬è¯´æ˜ v5.0:
# - ã€æ ¸å¿ƒæ–°å¢-æ™ºèƒ½è®°å¿†ã€‘é›†æˆChromaDBå‘é‡æ•°æ®åº“ã€‚
#   - ã€å†™å…¥ã€‘æ¯æ¬¡ç”Ÿæˆçš„æŠ¥å‘Šä¼šè‡ªåŠ¨å‘é‡åŒ–å¹¶å­˜å…¥ChromaDBï¼Œä½œä¸ºé•¿æœŸè®°å¿†ã€‚
#   - ã€è¯»å–ã€‘ç”Ÿæˆæ–°æŠ¥å‘Šæ—¶ï¼Œä¼šä»ChromaDBä¸­æ£€ç´¢æœ€ç›¸å…³çš„å†å²æ´å¯Ÿï¼Œæ³¨å…¥Promptã€‚
# - ã€æ ¸å¿ƒæ–°å¢-è¡¥å†™æ—¥æŠ¥ã€‘æ”¯æŒè¡¥å†™ä»»ä½•ä¸€å¤©çš„æ—¥æŠ¥ã€‚
#   - ä½¿ç”¨æ–°å‚æ•° `--date YYYY-MM-DD` æ¥æŒ‡å®šè¡¥å†™çš„æ—¥æœŸã€‚
# - ã€Promptå‡çº§ã€‘AI Promptç°å·²åŒ…å«ã€ç›¸å…³å†å²æ´å¯Ÿã€‘æ¨¡å—ï¼Œåˆ†ææ›´å…·è¿ç»­æ€§ã€‚
# - ã€ä¾èµ–æ›´æ–°ã€‘éœ€è¦å®‰è£… `chromadb` åº“ (`pip install chromadb`)ã€‚
# - ã€é…ç½®æ›´æ–°ã€‘éœ€è¦åœ¨ .env æ–‡ä»¶ä¸­é…ç½® `CHROMA_DB_PATH`ã€‚
# ==============================================================================

import os
import google.generativeai as genai
from notion_client import Client, APIResponseError
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta
import sys
import re
import threading
import argparse
import chromadb # ã€æ–°å¢ã€‘å¼•å…¥ChromaDB

def print_separator():
    print("\n" + "="*70 + "\n")

# --- æ¨¡å—ï¼šæ–‡æœ¬å‡€åŒ–å™¨ä¸è®­ç»ƒä¸­å¿ƒå†™å…¥ (v4.0åŸæ ·ä¿ç•™) ---
def clean_text(text):
    """æ–‡æœ¬å‡€åŒ–å™¨ï¼Œç§»é™¤æ— æ•ˆå­—ç¬¦ï¼Œç¡®ä¿APIè°ƒç”¨æˆåŠŸã€‚"""
    if not isinstance(text, str): return ""
    return re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', text)

def write_to_training_hub(notion, task_type, input_text, output_text, source_db_name, source_page_id, config):
    """å°†å¤ç›˜ä»»åŠ¡ä½œä¸ºè®­ç»ƒæ•°æ®å†™å…¥â€œAIè®­ç»ƒä¸­å¿ƒâ€æ•°æ®åº“ã€‚"""
    training_hub_db_id = config.get("TRAINING_HUB_DB_ID")
    if not training_hub_db_id:
        print(">> [è®­ç»ƒä¸­å¿ƒ] æœªé…ç½®æ•°æ®åº“ID (TRAINING_HUB_DATABASE_ID)ï¼Œè·³è¿‡å†™å…¥ã€‚")
        return

    try:
        safe_input_text = clean_text(str(input_text))[:1990]
        safe_output_text = clean_text(str(output_text))[:1990]
        training_title = f"ã€{task_type}ã€‘{datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d')} å‘¨æœŸæ€§æŠ¥å‘Šæ‘˜è¦"
        
        properties_data = {
            "è®­ç»ƒä»»åŠ¡": {"title": [{"text": {"content": training_title}}]},
            "ä»»åŠ¡ç±»å‹": {"select": {"name": task_type}},
            "æºæ•°æ® (Input)": {"rich_text": [{"text": {"content": safe_input_text}}]},
            "ç†æƒ³è¾“å‡º (Output)": {"rich_text": [{"text": {"content": safe_output_text}}]},
            "æ ‡æ³¨çŠ¶æ€": {"select": {"name": "å¾…å®¡æ ¸"}}
        }
        relation_column_map = {'DailyReview': config.get("RELATION_LINK_REVIEW_NAME", "æºé“¾æ¥-æ¯æ—¥å¤ç›˜")}
        if source_db_name in relation_column_map and source_page_id:
            column_to_update = relation_column_map[source_db_name]
            properties_data[column_to_update] = {"relation": [{"id": source_page_id}]}
        
        notion.pages.create(parent={"database_id": training_hub_db_id}, properties=properties_data)
        print(f">> [è®­ç»ƒä¸­å¿ƒ] å·²æˆåŠŸè®°å½•ä¸€æ¡ '{task_type}' è®­ç»ƒæ•°æ®ã€‚")

    except Exception as e:
        print(f"!! [è®­ç»ƒä¸­å¿ƒ] å†™å…¥æ—¶å‡ºé”™: {e}")

# --- ã€ã€ã€ æ–°å¢ï¼šå‘é‡æ•°æ®åº“æ ¸å¿ƒæ¨¡å— ã€‘ã€‘ã€‘ ---
class VectorMemory:
    def __init__(self, path, collection_name):
        self.client = None
        self.collection = None
        if not path or not collection_name:
            print("ğŸŸ¡ [è®°å¿†æ¨¡å—] æœªé…ç½®CHROMA_DB_PATHæˆ–CHROMA_COLLECTION_NAMEï¼Œå°†è·³è¿‡æ‰€æœ‰å‘é‡æ“ä½œã€‚")
            return
        try:
            print(f"ğŸ§  [è®°å¿†æ¨¡å—] æ­£åœ¨åˆå§‹åŒ–å‘é‡æ•°æ®åº“...")
            self.client = chromadb.PersistentClient(path=path)
            self.collection = self.client.get_or_create_collection(name=collection_name, metadata={"hnsw:space": "cosine"})
            print(f"  - æˆåŠŸè¿æ¥åˆ°é›†åˆ '{collection_name}'ã€‚")
        except Exception as e:
            print(f"âŒ [è®°å¿†æ¨¡å—] åˆå§‹åŒ–ChromaDBå¤±è´¥: {e}")
            self.client = None

    def add_memory(self, report_text, metadata):
        if not self.collection: return
        try:
            doc_id = f"{metadata['type']}-{metadata['date']}"
            print(f"  - æ­£åœ¨å°†æŠ¥å‘Š '{doc_id}' å‘é‡åŒ–å¹¶å­˜å…¥é•¿æœŸè®°å¿†...")
            embedding_model = 'models/embedding-001'
            embedding = genai.embed_content(model=embedding_model, content=report_text, task_type="RETRIEVAL_DOCUMENT")["embedding"]
            
            self.collection.add(
                embeddings=[embedding],
                documents=[report_text],
                metadatas=[metadata],
                ids=[doc_id]
            )
            print(f"  - âœ… è®°å¿†èƒ¶å›Š '{doc_id}' å·²æˆåŠŸå­˜å…¥å‘é‡æ•°æ®åº“ï¼")
        except Exception as e:
            print(f"  - âŒ [è®°å¿†æ¨¡å—] å­˜å…¥è®°å¿†æ—¶å‡ºé”™: {e}")

    def retrieve_memory(self, query_text, n_results=3):
        if not self.collection: return ""
        try:
            print(f"  - ğŸ§  æ­£åœ¨åŸºäºé—®é¢˜ '{query_text[:30]}...' æ£€ç´¢ç›¸å…³å†å²è®°å¿†...")
            embedding_model = 'models/embedding-001'
            query_embedding = genai.embed_content(model=embedding_model, content=query_text, task_type="RETRIEVAL_QUERY")["embedding"]

            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results
            )
            
            if not results or not results['documents'] or not results['documents'][0]:
                print("  - æœªæ‰¾åˆ°ç›¸å…³å†å²è®°å¿†ã€‚")
                return ""

            retrieved_docs = []
            for i, doc in enumerate(results['documents'][0]):
                meta = results['metadatas'][0][i]
                entry = f"--- å†å²æ´å¯Ÿ ({meta.get('date', 'æœªçŸ¥æ—¥æœŸ')} {meta.get('type', 'æŠ¥å‘Š')}):\n{doc}\n---"
                retrieved_docs.append(entry)
            
            print(f"  - âœ… æˆåŠŸæ£€ç´¢åˆ° {len(retrieved_docs)} æ¡ç›¸å…³å†å²è®°å¿†ã€‚")
            return "\n".join(retrieved_docs)
        except Exception as e:
            print(f"  - âŒ [è®°å¿†æ¨¡å—] æ£€ç´¢è®°å¿†æ—¶å‡ºé”™: {e}")
            return ""

# --- 1. åˆå§‹åŒ–ä¸é…ç½®åŠ è½½ (å·²å‡çº§) ---
def initialize():
    """åŠ è½½é…ç½®å¹¶åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
    print_separator()
    print("ğŸš€ å¯åŠ¨å‘¨æœŸæ€§å¤ç›˜AIå¼•æ“ (v5.0)...") # ã€ä¿®æ”¹ã€‘ç‰ˆæœ¬å·æ›´æ–°
    load_dotenv()
    config = {
        "NOTION_TOKEN": os.getenv("NOTION_API_KEY"),
        "API_KEY": os.getenv("GEMINI_API_KEY"),
        "LOG_DB_ID": os.getenv("TOOLBOX_LOG_DATABASE_ID"),
        "BRAIN_DB_ID": os.getenv("CORE_BRAIN_DATABASE_ID"),
        "CANDIDATE_DB_ID": os.getenv("CANDIDATE_DATABASE_ID"),
        "REVIEW_DB_ID": os.getenv("DAILY_REVIEW_DATABASE_ID"),
        "TRAINING_HUB_DB_ID": os.getenv("TRAINING_HUB_DATABASE_ID"),
        "RELATION_LINK_REVIEW_NAME": os.getenv("RELATION_LINK_REVIEW_NAME", "æºé“¾æ¥-æ¯æ—¥å¤ç›˜"),
        # --- ã€æ–°å¢é…ç½®ã€‘ ---
        "CHROMA_DB_PATH": os.getenv("CHROMA_DB_PATH"),
        "CHROMA_COLLECTION_NAME": os.getenv("CHROMA_COLLECTION_NAME")
    }
    if not all([config["NOTION_TOKEN"], config["API_KEY"], config["REVIEW_DB_ID"]]):
        print("âŒ é”™è¯¯ï¼šå…³é”®é…ç½®ç¼ºå¤±ï¼(NOTION_API_KEY, GEMINI_API_KEY, DAILY_REVIEW_DATABASE_ID å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­é…ç½®)")
        sys.exit(1)
    try:
        notion = Client(auth=config["NOTION_TOKEN"])
        genai.configure(api_key=config["API_KEY"])
        gemini_model = genai.GenerativeModel('models/gemini-2.5-pro') # ã€ä¿®æ”¹ã€‘è¿™é‡Œæˆ‘çœ‹åˆ°æ‚¨çš„ä»£ç ç”¨äº†flash-liteï¼Œä½†ä¸ºäº†é•¿è¿œè€ƒè™‘å’Œå…¼å®¹æ›´å¤æ‚çš„ä»»åŠ¡ï¼Œå»ºè®®ç”¨1.5-pro
        # --- ã€æ–°å¢ã€‘åˆå§‹åŒ–å‘é‡è®°å¿†æ¨¡å— ---
        memory = VectorMemory(config["CHROMA_DB_PATH"], config["CHROMA_COLLECTION_NAME"])
        print("âœ… Notion, Gemini API å’Œ å‘é‡è®°å¿†æ¨¡å— åˆå§‹åŒ–æˆåŠŸï¼")
        return notion, gemini_model, memory, config # ã€ä¿®æ”¹ã€‘å¢åŠ memoryè¿”å›
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}"); sys.exit(1)

# --- æ—¶é—´èŒƒå›´è®¡ç®— (å·²å‡çº§ï¼Œæ”¯æŒè¡¥å†™) ---
def get_date_range(report_type, specific_date_str=None):
    """æ ¹æ®æŠ¥å‘Šç±»å‹æˆ–æŒ‡å®šæ—¥æœŸè®¡ç®—å¼€å§‹å’Œç»“æŸæ—¥æœŸ"""
    # --- ã€æ–°å¢ã€‘è¡¥å†™æ—¥æŠ¥é€»è¾‘ ---
    if specific_date_str:
        try:
            beijing_tz = timezone(timedelta(hours=8))
            target_date = datetime.strptime(specific_date_str, '%Y-%m-%d')
            # å®šä¹‰åŒ—äº¬æ—¶é—´çš„å¼€å§‹å’Œç»“æŸ
            start_date_local = target_date.replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=beijing_tz)
            end_date_local = target_date.replace(hour=23, minute=59, second=59, microsecond=999999, tzinfo=beijing_tz)
            # è½¬æ¢ä¸ºUTCæ—¶é—´ä»¥ä¾›Notion APIæŸ¥è¯¢
            return start_date_local.astimezone(timezone.utc), end_date_local.astimezone(timezone.utc)
        except ValueError:
            print(f"âŒ æ—¥æœŸæ ¼å¼é”™è¯¯: '{specific_date_str}'ã€‚è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼ã€‚ç¨‹åºé€€å‡ºã€‚")
            sys.exit(1)
            
    # --- ä»¥ä¸‹æ˜¯v4.0çš„åŸæœ‰é€»è¾‘ ---
    end_date = datetime.now(timezone.utc)
    if report_type == 'daily':
        # ä¿®æ­£ä¸ºåŒ—äº¬æ—¶é—´å½“å¤©0ç‚¹åˆ°24ç‚¹
        today_beijing = datetime.now(timezone(timedelta(hours=8))).date()
        start_of_day_beijing = datetime.combine(today_beijing, datetime.min.time(), tzinfo=timezone(timedelta(hours=8)))
        start_date = start_of_day_beijing.astimezone(timezone.utc)
    elif report_type == 'weekly':
        start_date = end_date - timedelta(days=7)
    elif report_type == 'monthly':
        start_date = end_date - timedelta(days=30)
    elif report_type == 'quarterly':
        start_date = end_date - timedelta(days=90)
    elif report_type == 'yearly':
        start_date = end_date - timedelta(days=365)
    else: # é»˜è®¤ä¸ºæ—¥æŠ¥
        today_beijing = datetime.now(timezone(timedelta(hours=8))).date()
        start_of_day_beijing = datetime.combine(today_beijing, datetime.min.time(), tzinfo=timezone(timedelta(hours=8)))
        start_date = start_of_day_beijing.astimezone(timezone.utc)

    return start_date, end_date

# --- æ•°æ®æ‹‰å–å‡½æ•° (å·²å‡çº§ï¼Œæ”¯æŒç²¾ç¡®æ—¥æœŸèŒƒå›´) ---
def fetch_data_for_period(notion, db_id, db_name, start_date, end_date):
    """æ ¹æ®æŒ‡å®šçš„æ—¶é—´èŒƒå›´ä»Notionæ‹‰å–æ•°æ®"""
    if not db_id:
        print(f"ğŸŸ¡ è·³è¿‡ [{db_name}]ï¼šæœªåœ¨.envä¸­é…ç½®å…¶æ•°æ®åº“IDã€‚"); return ""
    print(f"â³ æ­£åœ¨ä» [{db_name}] æ•°æ®åº“æ‹‰å–å‘¨æœŸå†…æ•°æ®...")
    
    try:
        # ã€ä¿®æ”¹ã€‘è¿‡æ»¤å™¨å‡çº§ä¸ºå¤åˆè¿‡æ»¤å™¨ï¼Œä»¥æ”¯æŒç²¾ç¡®çš„å¼€å§‹å’Œç»“æŸæ—¥æœŸ
        response = notion.databases.query(
            database_id=db_id, 
            filter={
                "and": [
                    {"timestamp": "last_edited_time", "last_edited_time": {"on_or_after": start_date.isoformat()}},
                    {"timestamp": "last_edited_time", "last_edited_time": {"before": end_date.isoformat()}}
                ]
            }
        )
        pages = response.get("results", [])
        if not pages:
            print(f"  - åœ¨ [{db_name}] ä¸­æœªå‘ç°è¯¥å‘¨æœŸå†…çš„æ›´æ–°ã€‚"); return ""
        
        content_list = []
        for page in pages:
            title, properties = "[æ— æ ‡é¢˜]", page.get("properties", {})
            title_prop_names = ["ä¸»é¢˜", "æ—¥å¿—æ ‡é¢˜ åç§°", "å€™é€‰äººå§“å"]
            for prop_name in title_prop_names:
                if prop_name in properties and properties[prop_name].get("type") == "title":
                    title_parts = properties[prop_name].get("title", [])
                    if title_parts: title = title_parts[0].get("plain_text", "[ç©ºæ ‡é¢˜]"); break
            
            page_summary = f"\n--- è®°å½•æ¥æº: {db_name} | æ ‡é¢˜: {title} ---\n"
            if db_name == "AIå€™é€‰äººåˆ†æä¸­å¿ƒ":
                reason_prop = properties.get("è¯„åˆ†ç†ç”±", {}).get("rich_text", [])
                if reason_prop: page_summary += f"æ ¸å¿ƒè¯„ä»·: {reason_prop[0].get('plain_text', '')}\n"
            else: 
                try:
                    blocks_response = notion.blocks.children.list(block_id=page["id"], page_size=10)
                    for block in blocks_response.get("results", []):
                        if "paragraph" in block and "rich_text" in block["paragraph"]:
                            for text_part in block["paragraph"]["rich_text"]: page_summary += text_part.get("plain_text", "") + "\n"
                except APIResponseError: page_summary += "[æ— æ³•è·å–é¡µé¢æ­£æ–‡]\n"
            content_list.append(page_summary)
        
        print(f"  - æˆåŠŸä» [{db_name}] æ‹‰å– {len(pages)} æ¡è®°å½•ã€‚")
        return "\n".join(content_list)
    except APIResponseError as e:
        print(f"âŒ æŸ¥è¯¢ [{db_name}] æ—¶å‡ºé”™: {e}"); return ""


# --- AI Promptç”Ÿæˆå™¨ (å·²å‡çº§ï¼Œæ³¨å…¥å†å²è®°å¿†) ---
def get_prompt_for_report(report_type, data_text, start_date_str, end_date_str, historical_insights=""):
    """æ ¹æ®æŠ¥å‘Šç±»å‹ç”Ÿæˆä¸“å±çš„AI Prompt, å¹¶æ³¨å…¥å†å²æ´å¯Ÿ"""
    
    # --- ä»¥ä¸‹æ˜¯v4.0çš„åŸæœ‰ä»£ç  ---
    report_titles = {
        'daily': 'æ¯æ—¥æˆ˜ç•¥å¤ç›˜ä¸æœªæ¥è§„åˆ’', 'weekly': 'æ¯å‘¨æˆ˜ç•¥å›é¡¾ä¸å±•æœ›',
        'monthly': 'æœˆåº¦æˆ˜ç•¥å¤ç›˜ä¸ç›®æ ‡æ ¡å‡†', 'quarterly': 'å­£åº¦æ·±åº¦å¤ç›˜ä¸æˆ˜ç•¥è°ƒæ•´',
        'yearly': 'å¹´åº¦ç»¼åˆå¤ç›˜ä¸æœªæ¥æˆ˜ç•¥è§„åˆ’'
    }
    report_title = report_titles.get(report_type, 'å‘¨æœŸæ€§å¤ç›˜æŠ¥å‘Š')
    period_scopes = {
        'daily': ('ä»Šæ—¥', 'æ˜æ—¥'), 'weekly': ('æœ¬å‘¨', 'ä¸‹å‘¨'),
        'monthly': 'æœ¬æœˆ', 'quarterly': 'æœ¬å­£åº¦', 'yearly': 'æœ¬å¹´åº¦'
    }
    scope_texts = {
        'daily': ("ä»Šæ—¥æ ¸å¿ƒæˆæœæ¦‚è§ˆ", "æ˜æ—¥æ ¸å¿ƒä¼˜å…ˆäº‹é¡¹"),
        'weekly': ("æœ¬å‘¨æ ¸å¿ƒæˆæœä¸è¶‹åŠ¿", "ä¸‹å‘¨æ ¸å¿ƒç›®æ ‡ä¸ç­–ç•¥"),
        'monthly': ("æœ¬æœˆå…³é”®è¿›å±•ä¸æŒ‘æˆ˜", "ä¸‹æœˆæˆ˜ç•¥é‡ç‚¹"),
        'quarterly': ("æœ¬å­£åº¦é‡å¤§æˆå°±ä¸ç“¶é¢ˆ", "ä¸‹å­£åº¦æ ¸å¿ƒæˆ˜ç•¥æ–¹å‘"),
        'yearly': ("æœ¬å¹´åº¦æ ¸å¿ƒé‡Œç¨‹ç¢‘ä¸æ•™è®­", "ä¸‹ä¸€å¹´åº¦æˆ˜ç•¥è“å›¾")
    }
    current_scope, next_scope = scope_texts[report_type]

    # --- ã€æ–°å¢ã€‘å†å²æ´å¯Ÿéƒ¨åˆ† ---
    historical_context_section = ""
    if historical_insights:
        historical_context_section = f"""
# ç›¸å…³å†å²æ´å¯Ÿ (ä»æˆ‘çš„è®°å¿†åº“ä¸­æ£€ç´¢)
è¿™äº›æ˜¯è¿‡å»æœ€ç›¸å…³çš„æŠ¥å‘Šæ‘˜è¦ï¼Œè¯·åœ¨åˆ†ææ—¶å‚è€ƒï¼Œä»¥å‘ç°è¶‹åŠ¿å’Œè”ç³»ï¼š
{historical_insights}
---
"""
    # ã€ä¿®æ”¹ã€‘Promptæ¨¡æ¿ä¸­å¢åŠ äº† historical_context_section
    prompt = f"""
# è§’è‰²ä¸ä»»åŠ¡
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ã€å…·æœ‰è¿ç»­è®°å¿†çš„æˆ˜ç•¥é¡¾é—®ã€‚ä½ çš„ä»»åŠ¡æ˜¯ç»“åˆã€ç›¸å…³å†å²æ´å¯Ÿã€‘å’Œæˆ‘æä¾›çš„ã€å½“å‰å‘¨æœŸæ•°æ®ã€‘ï¼Œç”Ÿæˆä¸€ä»½æ·±åˆ»çš„ã€å…·æœ‰å‰åå…³è”æ€§çš„å¤ç›˜æŠ¥å‘Šã€‚

{historical_context_section}

# å½“å‰å¾…åˆ†ææ•°æ®
---
ã€{period_scopes[report_type][0] if isinstance(period_scopes[report_type], tuple) else period_scopes[report_type]}å·¥ä½œæ•°æ®æ±‡æ€» (ä» {start_date_str} åˆ° {end_date_str})ã€‘
{data_text}
---

# è¾“å‡ºæŒ‡ä»¤ä¸æ ¼å¼
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼è¾“å‡ºï¼Œåˆ†ä¸ºã€æŠ¥å‘Šä¸»ä½“ã€‘å’Œã€è¡ŒåŠ¨æŒ‡é’ˆã€‘ä¸¤éƒ¨åˆ†ã€‚åœ¨åˆ†ææ—¶ï¼Œè¯·ç‰¹åˆ«æ³¨æ„ã€å½“å‰å‘¨æœŸæ•°æ®ã€‘ä¸ã€ç›¸å…³å†å²æ´å¯Ÿã€‘ä¹‹é—´çš„è”ç³»ã€æ¼”å˜æˆ–çŸ›ç›¾ã€‚

### ç¬¬1éƒ¨åˆ†ï¼šæŠ¥å‘Šä¸»ä½“
---
## {report_title} - {end_date_str}
### 1. {current_scope} (Executive Summary)
*   **[ç”¨2-4ä¸ªè¦ç‚¹ï¼Œé«˜åº¦æ¦‚æ‹¬æœ¬å‘¨æœŸå†…çš„æ ¸å¿ƒäº§å‡ºã€å…³é”®è¶‹åŠ¿å’Œæ´»åŠ¨]**
### 2. äº®ç‚¹ä¸é«˜å…‰æ—¶åˆ» (Key Achievements & Highlights)
*   **[è¯†åˆ«å¹¶é˜è¿°1-3ä»¶æœ€æœ‰ä»·å€¼çš„äº‹ï¼Œå¹¶åˆ†æå…¶å¯¹äº {period_scopes[report_type][0] if isinstance(period_scopes[report_type], tuple) else period_scopes[report_type]} ç›®æ ‡çš„æˆ˜ç•¥æ„ä¹‰]**
### 3. ç“¶é¢ˆä¸æˆ˜ç•¥åæ€ (Bottlenecks & Strategic Reflections)
*   **[åˆ†ææœ¬å‘¨æœŸå†…é‡åˆ°çš„ä¸»è¦éšœç¢ã€æ•ˆç‡ç“¶é¢ˆï¼Œå¹¶è¿›è¡Œæ›´æ·±å±‚æ¬¡çš„æˆ˜ç•¥åŸå› åæ€ã€‚æ˜¯èµ„æºé—®é¢˜ï¼Ÿæ–¹å‘é—®é¢˜ï¼Ÿè¿˜æ˜¯æ‰§è¡Œé—®é¢˜ï¼Ÿ]**
### 4. è·¨å‘¨æœŸæ´å¯Ÿä¸æ¨¡å¼è¯†åˆ« (Cross-Period Insights & Pattern Recognition)
*   **æµ®ç°çš„ä¸»é¢˜:** [æœ¬å‘¨æœŸå†…åå¤å‡ºç°çš„æ–°ä¸»é¢˜æˆ–æ–°æœºä¼šæ˜¯ä»€ä¹ˆï¼Ÿ]
*   **æ¨¡å¼ä¸å…³è”:** [ä¸åŒå·¥ä½œä»»åŠ¡ä¹‹é—´æ˜¯å¦å­˜åœ¨å¯ä»¥åˆ©ç”¨çš„æ½œåœ¨å…³è”æˆ–æ¨¡å¼ï¼Ÿ]
*   **æˆ˜ç•¥å‡è®¾éªŒè¯:** [æœ¬å‘¨æœŸçš„å®è·µï¼Œæ˜¯éªŒè¯äº†è¿˜æ˜¯æŒ‘æˆ˜äº†æˆ‘ä»¬ä¹‹å‰çš„æˆ˜ç•¥å‡è®¾ï¼Ÿ]
### 5. {next_scope} ({'Priorities for Next Period' if report_type != 'daily' else 'Top Priorities for Tomorrow'})
- [ ] **[åŸºäºä»¥ä¸Šæ‰€æœ‰åˆ†æï¼Œç”Ÿæˆ2-4ä¸ªæœ€é‡è¦ã€æœ€å…·æˆ˜ç•¥ä»·å€¼çš„å¾…åŠäº‹é¡¹æˆ–ç›®æ ‡ï¼Œç”¨äºæŒ‡å¯¼ä¸‹ä¸€å‘¨æœŸ]**
- [ ] **[ç¬¬äºŒä¸ªå¾…åŠäº‹é¡¹]**
---

### ç¬¬2éƒ¨åˆ†ï¼šè¡ŒåŠ¨æŒ‡é’ˆ
åœ¨æŠ¥å‘Šä¸»ä½“ä¹‹åï¼Œä½ å¿…é¡»å¦èµ·ä¸€è¡Œï¼Œæä¾›ä¸€ä¸ªè¢« `<SUMMARY>` å’Œ `</SUMMARY>` æ ‡ç­¾åŒ…è£¹çš„ã€ä¸è¶…è¿‡ä¸¤å¥è¯çš„è¡ŒåŠ¨æŒ‡é’ˆã€‚è¿™ä¸ªæŒ‡é’ˆè¦é«˜åº¦æµ“ç¼©æŠ¥å‘Šä¸­æœ€æ ¸å¿ƒçš„ã€æœ€éœ€è¦æˆ‘å…³æ³¨çš„è¡ŒåŠ¨å»ºè®®ï¼Œä½œä¸ºä¸‹ä¸€å‘¨æœŸçš„æœ€é«˜æŒ‡å¯¼åŸåˆ™ã€‚
ã€ç¤ºä¾‹ã€‘: `<SUMMARY>ä¸‹å‘¨åº”é›†ä¸­ç²¾åŠ›å°†AIå€™é€‰äººåˆ†ææµç¨‹æ ‡å‡†åŒ–ï¼Œå¹¶å¯åŠ¨å¯¹'é¡¹ç›®X'çš„åˆæ­¥æŠ€æœ¯é¢„ç ”ï¼Œä»¥éªŒè¯å…¶é•¿æœŸä»·å€¼ã€‚</SUMMARY>`
"""
    return prompt

# --- 4. è°ƒç”¨AIè¿›è¡Œåˆ†æ (v4.0åŸæ ·ä¿ç•™) ---
def analyze_and_generate_report(gemini_model, prompt):
    print("ğŸ§  æ­£åœ¨è°ƒç”¨AIè¿›è¡Œæ·±åº¦æˆ˜ç•¥åˆ†æ...")
    print("   (æ•°æ®å·²å‘é€ç»™Googleï¼Œè®¾å®š3åˆ†é’Ÿè¶…æ—¶é™åˆ¶ï¼Œè¯·è€å¿ƒç­‰å¾…)...")
    try:
        response = gemini_model.generate_content(prompt, request_options={"timeout": 180})
        report_text = response.text
        print("âœ… AIæˆ˜ç•¥åˆ†æå®Œæˆï¼Œé«˜çº§æŠ¥å‘Šå·²ç”Ÿæˆï¼")
        return report_text
    except Exception as e:
        print(f"âŒ AIåˆ†ææ—¶å‡ºé”™ï¼ç¨‹åºä¸­æ–­ã€‚ é”™è¯¯è¯¦æƒ…: {e}"); return None

# --- 5. å°†æŠ¥å‘Šä¿å­˜å›Notion (å·²å‡çº§ï¼Œå¢åŠ å‘é‡è®°å¿†å†™å…¥) ---
def save_report_to_notion(notion, memory, config, report_type, report_text, original_data, start_date, end_date): #ã€ä¿®æ”¹ã€‘å¢åŠ memoryå‚æ•°
    """å°†æŠ¥å‘Šä¿å­˜åˆ°Notionï¼Œå¹¶è§¦å‘å‘é‡åŒ–å’Œè®­ç»ƒä¸­å¿ƒå†™å…¥ã€‚"""
    review_db_id = config["REVIEW_DB_ID"]
    
    report_type_map = {
        'daily': 'AIå¤ç›˜æŠ¥å‘Š', 'weekly': 'AIå‘¨æŠ¥', 'monthly': 'AIæœˆæŠ¥',
        'quarterly': 'AIå­£æŠ¥', 'yearly': 'AIå¹´æŠ¥'
    }
    report_notion_type = report_type_map.get(report_type, 'AIå¤ç›˜æŠ¥å‘Š')
    
    print(f"âœï¸ æ­£åœ¨å°†ã€{report_notion_type}ã€‘ä¿å­˜åˆ°'æ¯æ—¥å·¥ä½œæ—¥å¿—'æ•°æ®åº“...")
    
    summary, main_report = "", report_text
    start_tag, end_tag = "<SUMMARY>", "</SUMMARY>"
    start_index, end_index = report_text.find(start_tag), report_text.find(end_tag, report_text.find(start_tag))
    
    if start_index != -1 and end_index != -1:
        summary = report_text[start_index + len(start_tag):end_index].strip()
        main_report = report_text[:start_index].strip()
        print(f"  - å·²æˆåŠŸæå–è¡ŒåŠ¨æŒ‡é’ˆ: {summary}")
    else:
        print("  - æœªåœ¨AIå“åº”ä¸­æ‰¾åˆ°è¡ŒåŠ¨æŒ‡é’ˆæ ‡ç­¾ï¼Œè¯¥åˆ—å°†ä¸ºç©ºã€‚")
        main_report = report_text

    try:
        end_date_beijing = end_date.astimezone(timezone(timedelta(hours=8)))
        report_title = f"{end_date_beijing.strftime('%Y-%m-%d')} {report_notion_type}"

        properties_data = {
            "æ—¥å¿—æ ‡é¢˜ åç§°": {"title": [{"text": {"content": report_title}}]},
            "æ—¥æœŸ": {"date": {
                "start": start_date.astimezone(timezone(timedelta(hours=8))).isoformat(), 
                "end": end_date.astimezone(timezone(timedelta(hours=8))).isoformat()
            }},
            "æ¡ç›®ç±»å‹": {"select": {"name": report_notion_type}},
            "æœ¬æ—¥çŠ¶æ€å·¥ä½œçŠ¶æ€": {"select": {"name": "å·²å®Œæˆ"}},
        }
        if summary:
            properties_data["è¡ŒåŠ¨æŒ‡é’ˆ"] = {"rich_text": [{"text": {"content": summary}}]}
        
        children_blocks = [{
            "object": "block", "type": "callout",
            "callout": {
                "rich_text": [{"type": "text", "text": {"content": chunk}}],
                "icon": {"emoji": "ğŸ¯" if i == 0 else "ğŸ“„"},
                "color": "default"
            }
        } for i, chunk in enumerate([main_report[i:i + 1990] for i in range(0, len(main_report), 1990)])]

        new_page = notion.pages.create(parent={"database_id": review_db_id}, properties=properties_data, children=children_blocks)
        print(f"ğŸ‰ {report_notion_type}å·²æˆåŠŸä¿å­˜åˆ°Notionï¼")

        new_page_id = new_page.get('id')
        if new_page_id:
            # --- ã€æ–°å¢ã€‘å†™å…¥å‘é‡è®°å¿†å’Œè®­ç»ƒä¸­å¿ƒ ---
            # 1. å‘é‡åŒ–å†™å…¥
            if memory.client:
                memory_metadata = {'type': report_type, 'date': end_date_beijing.strftime('%Y-%m-%d')}
                threading.Thread(target=memory.add_memory, args=(main_report, memory_metadata), daemon=True).start()

            # 2. è®­ç»ƒä¸­å¿ƒå†™å…¥ (v4.0åŸæœ‰é€»è¾‘)
            print(">> æ­£åœ¨å¯åŠ¨åå°ä»»åŠ¡ï¼Œå°†æœ¬æ¬¡å¤ç›˜å­˜å…¥ [AIè®­ç»ƒä¸­å¿ƒ] ...")
            threading.Thread(
                target=write_to_training_hub,
                args=(notion, "æ‘˜è¦ç”Ÿæˆ", original_data, main_report, 'DailyReview', new_page_id, config),
                daemon=True
            ).start()

    except APIResponseError as e:
        print(f"âŒ ä¿å­˜åˆ°Notionå¤±è´¥: {e.code} - {e.body}")
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ°Notionæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# --- ä¸»ç¨‹åºå…¥å£ (å·²å…¨é¢å‡çº§) ---
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="å‘¨æœŸæ€§å¤ç›˜AI v5.0") #ã€ä¿®æ”¹ã€‘ç‰ˆæœ¬å·
    parser.add_argument(
        '--type', 
        type=str, 
        choices=['daily', 'weekly', 'monthly', 'quarterly', 'yearly'], 
        default='daily',
        help="æŒ‡å®šè¦ç”Ÿæˆçš„æŠ¥å‘Šç±»å‹ (é»˜è®¤: daily)"
    )
    # --- ã€æ–°å¢ã€‘è¡¥å†™æ—¥æœŸå‚æ•° ---
    parser.add_argument(
        '--date', 
        type=str,
        default=None,
        help="è¡¥å†™æŒ‡å®šæ—¥æœŸçš„æ—¥æŠ¥ï¼Œæ ¼å¼ä¸º YYYY-MM-DDã€‚ä½¿ç”¨æ­¤å‚æ•°æ—¶å°†å¿½ç•¥ --typeã€‚"
    )
    args = parser.parse_args()
    
    # ã€ä¿®æ”¹ã€‘åˆå§‹åŒ–è°ƒç”¨
    notion, gemini_model, memory, config = initialize()
    
    # 1. ã€ä¿®æ”¹ã€‘æ ¹æ®å‚æ•°ç¡®å®šæŠ¥å‘Šç±»å‹å’Œæ—¶é—´èŒƒå›´
    if args.date:
        report_type = 'daily' # è¡¥å†™åŠŸèƒ½åªé’ˆå¯¹æ—¥æŠ¥
        start_date, end_date = get_date_range(report_type, specific_date_str=args.date)
        print(f"æ¨¡å¼åˆ‡æ¢ï¼šè¡¥å†™æ—¥æŠ¥æ¨¡å¼")
    else:
        report_type = args.type
        start_date, end_date = get_date_range(report_type)

    beijing_tz = timezone(timedelta(hours=8))
    start_date_str = start_date.astimezone(beijing_tz).strftime('%Y-%m-%d')
    end_date_str = end_date.astimezone(beijing_tz).strftime('%Y-%m-%d')
    print_separator()
    print(f"ğŸ“Š æŠ¥å‘Šç±»å‹: {report_type.upper()} | æ•°æ®å‘¨æœŸ: {start_date_str} to {end_date_str}")
    
    # 2. ã€ä¿®æ”¹ã€‘æ‹‰å–å‘¨æœŸå†…æ•°æ®ï¼Œä¼ å…¥end_date
    log_data = fetch_data_for_period(notion, config["LOG_DB_ID"], "AIäº’åŠ¨æ—¥å¿—", start_date, end_date)
    brain_data = fetch_data_for_period(notion, config["BRAIN_DB_ID"], "AIä½œæˆ˜æŒ‡æŒ¥å®¤", start_date, end_date)
    candidate_data = fetch_data_for_period(notion, config["CANDIDATE_DB_ID"], "AIå€™é€‰äººåˆ†æä¸­å¿ƒ", start_date, end_date)
    
    full_period_data = (f"--- æ•°æ®æ¥æº: AIäº’åŠ¨æ—¥å¿— ---\n{log_data}\n\n"
                        f"--- æ•°æ®æ¥æº: AIä½œæˆ˜æŒ‡æŒ¥å®¤ ---\n{brain_data}\n\n"
                        f"--- æ•°æ®æ¥æº: AIå€™é€‰äººåˆ†æä¸­å¿ƒ ---\n{candidate_data}")
                       
    if len(full_period_data.strip()) < 150: 
        print(f"\nğŸŸ¡ è¯¥å‘¨æœŸå†…æ ¸å¿ƒæ•°æ®åº“æ— è¶³å¤Ÿæ•°æ®å¯ä¾›åˆ†æ ({len(full_period_data.strip())} å­—ç¬¦)ï¼Œç¨‹åºé€€å‡ºã€‚")
    else:
        # 3. ã€æ–°å¢ã€‘æ£€ç´¢ç›¸å…³å†å²è®°å¿†
        query_for_memory = f"ä¸ºæˆ‘çš„{report_type}æŠ¥å‘Šï¼Œæ€»ç»“è¿‡å»çš„æ ¸å¿ƒæˆå°±ã€æŒ‘æˆ˜å’Œæœªæ¥æ–¹å‘ã€‚"
        historical_insights = memory.retrieve_memory(query_for_memory)
        
        # 4. ã€ä¿®æ”¹ã€‘è·å–ä¸“å±Promptå¹¶ç”ŸæˆæŠ¥å‘Šï¼Œä¼ å…¥å†å²æ´å¯Ÿ
        prompt = get_prompt_for_report(report_type, full_period_data, start_date_str, end_date_str, historical_insights)
        final_report_with_summary = analyze_and_generate_report(gemini_model, prompt)
        
        if final_report_with_summary:
            # 5. ã€ä¿®æ”¹ã€‘ä¿å­˜æŠ¥å‘Šåˆ°Notionå’Œå‘é‡æ•°æ®åº“
            save_report_to_notion(
                notion, memory, config, report_type, final_report_with_summary, 
                full_period_data, start_date, end_date
            )
            
    print_separator()
    input("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œè¯·æŒ‰å›è½¦é”®é€€å‡ºã€‚")