# ==============================================================================
#                      æ¯æ—¥å¤ç›˜AI (Daily Review AI) v3.8
#                      (Training Hub Integrated Edition)
# ==============================================================================
# ç‰ˆæœ¬è¯´æ˜:
# - ã€æ ¸å¿ƒæ–°å¢ã€‘æ— ç¼é›†æˆäº†â€œAIè®­ç»ƒä¸­å¿ƒâ€æ¨¡å—ã€‚
# - ã€è‡ªåŠ¨å½’æ¡£ã€‘æ¯æ¬¡æˆåŠŸçš„æ¯æ—¥å¤ç›˜ï¼Œéƒ½ä¼šè‡ªåŠ¨å°†â€œåŸå§‹æ•°æ®æ±‡æ€»â€å’Œâ€œAIæŠ¥å‘Šâ€
#              ä½œä¸ºä¸€æ¡â€œæ‘˜è¦ç”Ÿæˆâ€ä»»åŠ¡ï¼Œå­˜å…¥æ‚¨çš„[AIè®­ç»ƒä¸­å¿ƒ]æ•°æ®åº“ã€‚
# - ã€ä¸¥æ ¼éµå®ˆã€‘ç¡®ä¿v3.7æ‰€æœ‰åŸæœ‰åŠŸèƒ½ï¼ˆåŒ…æ‹¬è¶…é•¿æŠ¥å‘Šåˆ‡åˆ†ï¼‰100%ä¿ç•™ã€‚
# ==============================================================================

import os
import google.generativeai as genai
from notion_client import Client, APIResponseError
from dotenv import load_dotenv
from datetime import datetime, timezone, timedelta
import sys
import re
import threading

def print_separator():
    print("\n" + "="*70 + "\n")

# --- ã€ã€ã€ æ–°å¢ï¼šç§»æ¤è‡ªv9.5å·¥å…·ç®±çš„æ ¸å¿ƒæ¨¡å— ã€‘ã€‘ã€‘ ---
def clean_text(text):
    """æ–‡æœ¬å‡€åŒ–å™¨ï¼Œç§»é™¤æ— æ•ˆå­—ç¬¦ï¼Œç¡®ä¿APIè°ƒç”¨æˆåŠŸã€‚"""
    if not isinstance(text, str): return ""
    return re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F-\x9F]', '', text)

def write_to_training_hub(notion, task_type, input_text, output_text, source_db_name, source_page_id, config):
    """å°†å¤ç›˜ä»»åŠ¡ä½œä¸ºè®­ç»ƒæ•°æ®å†™å…¥â€œAIè®­ç»ƒä¸­å¿ƒâ€æ•°æ®åº“ã€‚"""
    training_hub_db_id = config.get("TRAINING_HUB_DB_ID")
    if not training_hub_db_id:
        print(">> [è®­ç»ƒä¸­å¿ƒ] æœªé…ç½®æ•°æ®åº“ID (TRAINING_HUB_DATABASE_ID)ï¼Œè·³è¿‡å†™å…¥ã€‚")
        return

    try:
        # æ¸…ç†å¹¶æˆªæ–­æ–‡æœ¬ä»¥ç¬¦åˆNotioné™åˆ¶
        safe_input_text = clean_text(str(input_text))[:1990]
        safe_output_text = clean_text(str(output_text))[:1990]
        
        training_title = f"ã€{task_type}ã€‘{datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d')} å¤ç›˜æ‘˜è¦"
        
        properties_data = {
            "è®­ç»ƒä»»åŠ¡": {"title": [{"text": {"content": training_title}}]},
            "ä»»åŠ¡ç±»å‹": {"select": {"name": task_type}},
            "æºæ•°æ® (Input)": {"rich_text": [{"text": {"content": safe_input_text}}]},
            "ç†æƒ³è¾“å‡º (Output)": {"rich_text": [{"text": {"content": safe_output_text}}]},
            "æ ‡æ³¨çŠ¶æ€": {"select": {"name": "å¾…å®¡æ ¸"}}
        }

        # åŠ¨æ€å¤„ç†å…³è”åˆ—
        relation_column_map = {
            'DailyReview': config.get("RELATION_LINK_REVIEW_NAME", "æºé“¾æ¥-æ¯æ—¥å¤ç›˜"),
        }
        
        if source_db_name in relation_column_map and source_page_id:
            column_to_update = relation_column_map[source_db_name]
            properties_data[column_to_update] = {"relation": [{"id": source_page_id}]}
        
        notion.pages.create(parent={"database_id": training_hub_db_id}, properties=properties_data)
        print(f">> [è®­ç»ƒä¸­å¿ƒ] å·²æˆåŠŸè®°å½•ä¸€æ¡ '{task_type}' è®­ç»ƒæ•°æ®ã€‚")

    except Exception as e:
        print(f"!! [è®­ç»ƒä¸­å¿ƒ] å†™å…¥æ—¶å‡ºé”™: {e}")

# --- 1. åˆå§‹åŒ–ä¸é…ç½®åŠ è½½ (å·²å‡çº§) ---
def initialize():
    """åŠ è½½é…ç½®å¹¶åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡"""
    print_separator()
    print("ğŸš€ å¯åŠ¨æ¯æ—¥å¤ç›˜AIå¼•æ“ (v3.8 - Training Hub Integrated)...")
    load_dotenv()
    config = {
        "NOTION_TOKEN": os.getenv("NOTION_API_KEY"),
        "API_KEY": os.getenv("GEMINI_API_KEY"),
        "LOG_DB_ID": os.getenv("TOOLBOX_LOG_DATABASE_ID"),
        "BRAIN_DB_ID": os.getenv("CORE_BRAIN_DATABASE_ID"),
        "CANDIDATE_DB_ID": os.getenv("CANDIDATE_DATABASE_ID"),
        "REVIEW_DB_ID": os.getenv("DAILY_REVIEW_DATABASE_ID"),
        # --- ã€ã€ã€ æ–°å¢é…ç½®é¡¹ ã€‘ã€‘ã€‘ ---
        "TRAINING_HUB_DB_ID": os.getenv("TRAINING_HUB_DATABASE_ID"),
        "RELATION_LINK_REVIEW_NAME": os.getenv("RELATION_LINK_REVIEW_NAME", "æºé“¾æ¥-æ¯æ—¥å¤ç›˜") # å…è®¸åœ¨.envä¸­è‡ªå®šä¹‰åˆ—å
    }
    if not all([config["NOTION_TOKEN"], config["API_KEY"], config["REVIEW_DB_ID"]]):
        print("âŒ é”™è¯¯ï¼šå…³é”®é…ç½®ç¼ºå¤±ï¼(NOTION_API_KEY, GEMINI_API_KEY, DAILY_REVIEW_DATABASE_ID å¿…é¡»åœ¨ .env æ–‡ä»¶ä¸­é…ç½®)")
        sys.exit(1)
    try:
        notion = Client(auth=config["NOTION_TOKEN"])
        genai.configure(api_key=config["API_KEY"])
        gemini_model = genai.GenerativeModel('models/gemini-2.5-pro') 
        print("âœ… Notion å’Œ Gemini API åˆå§‹åŒ–æˆåŠŸï¼")
        return notion, gemini_model, config
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}"); sys.exit(1)

# --- 2. ä»Notionæ‹‰å–å½“æ—¥æ•°æ® (åŸæ ·ä¿ç•™ v3.7) ---
def fetch_todays_data(notion, db_id, db_name):
    if not db_id:
        print(f"ğŸŸ¡ è·³è¿‡ [{db_name}]ï¼šæœªåœ¨.envä¸­é…ç½®å…¶æ•°æ®åº“IDã€‚"); return ""
    print(f"â³ æ­£åœ¨ä» [{db_name}] æ•°æ®åº“æ‹‰å–ä»Šæ—¥æ•°æ®...")
    today_utc = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)
    try:
        response = notion.databases.query(database_id=db_id, filter={"timestamp": "last_edited_time", "last_edited_time": {"on_or_after": today_utc.isoformat()}})
        pages = response.get("results", [])
        if not pages:
            print(f"  - åœ¨ [{db_name}] ä¸­æœªå‘ç°ä»Šæ—¥æ›´æ–°ã€‚"); return ""
        content_list = []
        for page in pages:
            title, properties = "[æ— æ ‡é¢˜]", page.get("properties", {})
            title_prop_names = ["ä¸»é¢˜", "æ—¥å¿—æ ‡é¢˜ åç§°", "å€™é€‰äººå§“å"]
            for prop_name in title_prop_names:
                if prop_name in properties and properties[prop_name].get("type") == "title":
                    title_parts = properties[prop_name].get("title", [])
                    if title_parts: title = title_parts[0].get("plain_text", "[ç©ºæ ‡é¢˜]"); break
            page_summary = f"\n--- è®°å½•æ¥æº: {db_name} | æ ‡é¢˜: {title} ---\n"
            if db_name == "AIå€™é€‰äººåˆ†æä¸­å¿ƒ":
                reason_prop = properties.get("è¯„åˆ†ç†ç”±", {}).get("rich_text", [])
                if reason_prop: page_summary += f"æ ¸å¿ƒè¯„ä»·: {reason_prop[0].get('plain_text', '')}\n"
            else: 
                try:
                    blocks_response = notion.blocks.children.list(block_id=page["id"], page_size=10)
                    for block in blocks_response.get("results", []):
                        if "paragraph" in block and "rich_text" in block["paragraph"]:
                            for text_part in block["paragraph"]["rich_text"]: page_summary += text_part.get("plain_text", "") + "\n"
                except APIResponseError: page_summary += "[æ— æ³•è·å–é¡µé¢æ­£æ–‡]\n"
            content_list.append(page_summary)
        print(f"  - æˆåŠŸä» [{db_name}] æ‹‰å– {len(pages)} æ¡è®°å½•ã€‚")
        return "\n".join(content_list)
    except APIResponseError as e:
        print(f"âŒ æŸ¥è¯¢ [{db_name}] æ—¶å‡ºé”™: {e}"); return ""

# --- 3. è°ƒç”¨AIè¿›è¡Œåˆ†æ (åŸæ ·ä¿ç•™ v3.7) ---
def analyze_and_generate_report(gemini_model, daily_data_text):
    print("ğŸ§  æ­£åœ¨è°ƒç”¨AIè¿›è¡Œæ·±åº¦æˆ˜ç•¥åˆ†æä¸è§„åˆ’...")
    print("   (æ•°æ®å·²å‘é€ç»™Googleï¼Œè®¾å®š3åˆ†é’Ÿè¶…æ—¶é™åˆ¶ï¼Œè¯·è€å¿ƒç­‰å¾…)...")
    prompt = f"""
# è§’è‰²ä¸ä»»åŠ¡
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„æˆ˜ç•¥é¡¾é—®ã€‚åŸºäºæˆ‘æä¾›çš„ã€ä»Šæ—¥å·¥ä½œæ•°æ®æ±‡æ€»ã€‘ï¼Œå®Œæˆä¸¤é¡¹ä»»åŠ¡ï¼š
1.  ç”Ÿæˆä¸€ä»½è¯¦ç»†çš„â€œæ¯æ—¥æˆ˜ç•¥å¤ç›˜ä¸æœªæ¥è§„åˆ’æŠ¥å‘Šâ€ã€‚
2.  æç‚¼å‡ºä¸€ä¸ªæå…¶ç²¾ç‚¼çš„â€œè¡ŒåŠ¨æŒ‡é’ˆâ€æ€»ç»“ã€‚

# å¾…åˆ†ææ•°æ®
---
ã€ä»Šæ—¥å·¥ä½œæ•°æ®æ±‡æ€»ã€‘
{daily_data_text}
---

# è¾“å‡ºæŒ‡ä»¤ä¸æ ¼å¼
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œåˆ†ä¸ºã€æŠ¥å‘Šä¸»ä½“ã€‘å’Œã€è¡ŒåŠ¨æŒ‡é’ˆã€‘ä¸¤éƒ¨åˆ†ã€‚

### ç¬¬1éƒ¨åˆ†ï¼šæŠ¥å‘Šä¸»ä½“
è¯·ä½¿ç”¨ä»¥ä¸‹Markdownæ ¼å¼ç”ŸæˆæŠ¥å‘Šã€‚
---
## æ¯æ—¥æˆ˜ç•¥å¤ç›˜ä¸æœªæ¥è§„åˆ’ - {datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%d')}
### 1. ä»Šæ—¥æ ¸å¿ƒæˆæœæ¦‚è§ˆ (Executive Summary)
*   **[ç”¨2-3ä¸ªè¦ç‚¹ï¼Œæ¦‚æ‹¬æ ¸å¿ƒäº§å‡ºä¸æ´»åŠ¨]**
### 2. äº®ç‚¹ä¸é«˜å…‰æ—¶åˆ» (Key Achievements & Highlights)
*   **[è¯†åˆ«å¹¶é˜è¿°1-2ä»¶æœ€æœ‰ä»·å€¼çš„äº‹åŠå…¶æˆ˜ç•¥æ„ä¹‰]**
### 3. ç“¶é¢ˆä¸æ½œåœ¨é£é™©åˆ†æ (Bottlenecks & Potential Risks)
*   **[åˆ†ææ•ˆç‡ç“¶é¢ˆã€é‡å¤åŠ³åŠ¨æˆ–æ½œåœ¨é£é™©]**
### 4. å…·ä½“æµç¨‹æ”¹è¿›å»ºè®® (Process Improvement Suggestions)
*   **å…³äºæ‹›è˜æµç¨‹:** [æå‡ºå…·ä½“æ”¹è¿›æªæ–½]
*   **å…³äºçŸ¥è¯†ç®¡ç†:** [æå‡ºå…·ä½“æ”¹è¿›æªæ–½]
*   **å…³äºAIå·¥å…·é“¾:** [æå‡ºå…·ä½“æ”¹è¿›æªæ–½]
### 5. å®è§‚æ´å¯Ÿä¸æœªæ¥æ–¹å‘ (Macro-Level Insights & Future Directions)
*   **æµ®ç°çš„ä¸»é¢˜:** [å‘ç°æ–°çš„æˆ˜ç•¥é‡ç‚¹]
*   **è·¨é¢†åŸŸè¿æ¥:** [å‘ç°ä¸åŒå·¥ä½œé—´çš„å…³è”]
*   **æ–°é¡¹ç›®/æ–°AIå­µåŒ–å»ºè®®:** [æå‡ºæ–°çš„é¡¹ç›®ç‚¹å­]
### 6. æ˜æ—¥æ ¸å¿ƒä¼˜å…ˆäº‹é¡¹ (Top Priorities for Tomorrow)
- [ ] **[ç”Ÿæˆ2-3ä¸ªæœ€é‡è¦çš„å¾…åŠäº‹é¡¹]**
- [ ] **[ç¬¬äºŒä¸ªå¾…åŠäº‹é¡¹]**
---

### ç¬¬2éƒ¨åˆ†ï¼šè¡ŒåŠ¨æŒ‡é’ˆ
åœ¨æŠ¥å‘Šä¸»ä½“ä¹‹åï¼Œä½ å¿…é¡»å¦èµ·ä¸€è¡Œï¼Œæä¾›ä¸€ä¸ªè¢« `<SUMMARY>` å’Œ `</SUMMARY>` æ ‡ç­¾åŒ…è£¹çš„ã€ä¸è¶…è¿‡ä¸¤å¥è¯çš„è¡ŒåŠ¨æŒ‡é’ˆã€‚è¿™ä¸ªæŒ‡é’ˆè¦é«˜åº¦æµ“ç¼©æŠ¥å‘Šä¸­æœ€æ ¸å¿ƒçš„ã€æœ€éœ€è¦æˆ‘å…³æ³¨çš„è¡ŒåŠ¨å»ºè®®ã€‚
ã€ç¤ºä¾‹ã€‘: `<SUMMARY>æ˜æ—¥åº”ä¼˜å…ˆç³»ç»ŸåŒ–æ•´ç†ä»Šæ—¥å…³äºXXæŠ€æœ¯çš„é›¶æ•£ç¬”è®°ï¼Œå¹¶åŸºäºæ­¤è°ƒæ•´æ‹›è˜JDçš„å…³é”®è¯ä»¥å¸å¼•æ›´ç²¾å‡†çš„å€™é€‰äººã€‚</SUMMARY>`
"""
    try:
        response = gemini_model.generate_content(prompt, request_options={"timeout": 180})
        report_text = response.text
        print("âœ… AIæˆ˜ç•¥åˆ†æå®Œæˆï¼Œé«˜çº§æŠ¥å‘Šå·²ç”Ÿæˆï¼")
        return report_text
    except Exception as e:
        print(f"âŒ AIåˆ†ææ—¶å‡ºé”™ï¼ç¨‹åºä¸­æ–­ã€‚ é”™è¯¯è¯¦æƒ…: {e}"); return None

# --- 4. å°†æŠ¥å‘Šä¿å­˜å›Notion (å·²å‡çº§) ---
def save_report_to_notion(notion, config, report_text, original_data):
    """å°†æŠ¥å‘Šä¿å­˜åˆ°Notionï¼Œå¹¶ã€è§¦å‘ã€‘ä¿å­˜è®­ç»ƒæ•°æ®åˆ°AIè®­ç»ƒä¸­å¿ƒã€‚"""
    review_db_id = config["REVIEW_DB_ID"]
    print("âœï¸ æ­£åœ¨å°†å¤ç›˜æŠ¥å‘Šä¿å­˜åˆ°'æ¯æ—¥å·¥ä½œæ—¥å¿—'æ•°æ®åº“...")
    summary, main_report = "", report_text
    start_tag, end_tag = "<SUMMARY>", "</SUMMARY>"
    start_index, end_index = report_text.find(start_tag), report_text.find(end_tag, report_text.find(start_tag))
    
    if start_index != -1 and end_index != -1:
        summary = report_text[start_index + len(start_tag):end_index].strip()
        main_report = report_text[:start_index].strip()
        print(f"  - å·²æˆåŠŸæå–è¡ŒåŠ¨æŒ‡é’ˆ: {summary}")
    else:
        print("  - æœªåœ¨AIå“åº”ä¸­æ‰¾åˆ°è¡ŒåŠ¨æŒ‡é’ˆæ ‡ç­¾ï¼Œè¯¥åˆ—å°†ä¸ºç©ºã€‚")
        main_report = report_text # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œæ•´ä¸ªæ–‡æœ¬éƒ½æ˜¯æŠ¥å‘Šä¸»ä½“

    try:
        beijing_time = datetime.now(timezone(timedelta(hours=8)))
        today_str, today_iso = beijing_time.strftime('%Y-%m-%d'), beijing_time.isoformat()
        
        properties_data = {
            "æ—¥å¿—æ ‡é¢˜ åç§°": {"title": [{"text": {"content": f"{today_str} AIæˆ˜ç•¥å¤ç›˜æŠ¥å‘Š"}}]},
            "æ—¥æœŸ": {"date": {"start": today_iso}},
            "æ¡ç›®ç±»å‹": {"select": {"name": "AIå¤ç›˜æŠ¥å‘Š"}},
            "æœ¬æ—¥çŠ¶æ€å·¥ä½œçŠ¶æ€": {"select": {"name": "å·²å®Œæˆ"}},
        }
        if summary:
            properties_data["è¡ŒåŠ¨æŒ‡é’ˆ"] = {"rich_text": [{"text": {"content": summary}}]}
        
        # v3.7 ç»ˆæå®Œç¾ä¿®å¤ (åŸæ ·ä¿ç•™)
        children_blocks = [{
            "object": "block", "type": "callout",
            "callout": {
                "rich_text": [{"type": "text", "text": {"content": chunk}}],
                "icon": {"emoji": "ğŸ¯" if i == 0 else "ğŸ“„"},
                "color": "default"
            }
        } for i, chunk in enumerate([main_report[i:i + 1990] for i in range(0, len(main_report), 1990)])]

        # --- ã€ã€ã€ æ ¸å¿ƒæ”¹åŠ¨ç‚¹ ã€‘ã€‘ã€‘ ---
        # 1. åˆ›å»ºé¡µé¢ï¼Œå¹¶æ¥æ”¶è¿”å›çš„é¡µé¢å¯¹è±¡
        new_page = notion.pages.create(parent={"database_id": review_db_id}, properties=properties_data, children=children_blocks)
        print("ğŸ‰ æ¯æ—¥æˆ˜ç•¥å¤ç›˜æŠ¥å‘Šå·²æˆåŠŸä¿å­˜åˆ°Notionï¼")

        # 2. ä»è¿”å›å¯¹è±¡ä¸­è·å–æ–°é¡µé¢çš„ID
        new_page_id = new_page.get('id')
        
        # 3. å¦‚æœæˆåŠŸè·å–IDï¼Œåˆ™åœ¨åå°çº¿ç¨‹ä¸­è°ƒç”¨å†™å…¥è®­ç»ƒä¸­å¿ƒçš„åŠŸèƒ½
        if new_page_id:
            print(">> æ­£åœ¨å¯åŠ¨åå°ä»»åŠ¡ï¼Œå°†æœ¬æ¬¡å¤ç›˜å­˜å…¥ [AIè®­ç»ƒä¸­å¿ƒ] ...")
            threading.Thread(
                target=write_to_training_hub,
                args=(
                    notion, "æ‘˜è¦ç”Ÿæˆ", original_data, main_report, 
                    'DailyReview', new_page_id, config
                ),
                daemon=True
            ).start()
        # --- ã€ã€ã€ æ”¹åŠ¨ç»“æŸ ã€‘ã€‘ã€‘ ---

    except APIResponseError as e:
        print(f"âŒ ä¿å­˜åˆ°Notionå¤±è´¥: {e.code} - {e.body}")
    except Exception as e:
        print(f"âŒ ä¿å­˜åˆ°Notionæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")

# --- ä¸»ç¨‹åºå…¥å£ (å·²å‡çº§) ---
if __name__ == "__main__":
    notion, gemini_model, config = initialize()
    
    log_data = fetch_todays_data(notion, config["LOG_DB_ID"], "AIäº’åŠ¨æ—¥å¿—")
    brain_data = fetch_todays_data(notion, config["BRAIN_DB_ID"], "AIä½œæˆ˜æŒ‡æŒ¥å®¤")
    candidate_data = fetch_todays_data(notion, config["CANDIDATE_DB_ID"], "AIå€™é€‰äººåˆ†æä¸­å¿ƒ")
    
    full_daily_data = (f"--- æ•°æ®æ¥æº: AIäº’åŠ¨æ—¥å¿— ---\n{log_data}\n\n"
                       f"--- æ•°æ®æ¥æº: AIä½œæˆ˜æŒ‡æŒ¥å®¤ ---\n{brain_data}\n\n"
                       f"--- æ•°æ®æ¥æº: AIå€™é€‰äººåˆ†æä¸­å¿ƒ ---\n{candidate_data}")
                       
    if len(full_daily_data.strip()) < 150: 
        print("\nğŸŸ¡ ä»Šæ—¥æ ¸å¿ƒæ•°æ®åº“æ— è¶³å¤Ÿæ•°æ®å¯ä¾›åˆ†æï¼Œç¨‹åºé€€å‡ºã€‚")
    else:
        final_report_with_summary = analyze_and_generate_report(gemini_model, full_daily_data)
        if final_report_with_summary:
            # ã€å‡çº§ã€‘å°†åŸå§‹æ•°æ®ä¹Ÿä¼ å…¥ï¼Œä»¥ä¾¿å†™å…¥è®­ç»ƒä¸­å¿ƒ
            save_report_to_notion(notion, config, final_report_with_summary, full_daily_data)
            
    print_separator()
    input("æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼Œè¯·æŒ‰å›è½¦é”®é€€å‡ºã€‚")